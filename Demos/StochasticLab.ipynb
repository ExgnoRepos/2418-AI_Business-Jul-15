{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e9e317-3a44-46df-8a8e-f9eafdfde300",
   "metadata": {},
   "source": [
    "# Stochastic Regression Lab\n",
    "In this lab you will use stochastic regression to categorize our favourite dataset, the MNIST handwritten digits\n",
    "\n",
    "The Python libary we will be using is the PyTorch library\n",
    "\n",
    "Use the pytorch 2.0.0 Python 3.10 CPU Optmized kernel\n",
    "\n",
    "## Step One -- Import the libraries we need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8c911-444e-409a-a8bf-4b24c6112265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95e840-01e6-4d92-a228-f3a466526019",
   "metadata": {},
   "source": [
    "## Step Two -- Getting the Data\n",
    "\n",
    "The MNIST dataset is part of the PyTorch library\n",
    "\n",
    "Load 6000 images for training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce3983-a186-42a1-90f1-a98df8a70950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604af4c7-3130-42ce-b9ef-6d3ea1ee5fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Now load 1000 images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8294294d-2677-41db-bf3b-63dd03079dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c01e9b-f9e9-4789-b122-2e7b0c36ee16",
   "metadata": {},
   "source": [
    "Confirm the number of images in the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb546d36-9449-4509-868c-a9c3adf2950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of training samples: \" + str(len(train_dataset)) + \"\\n\" +\n",
    "      \"number of testing samples: \" + str(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d30c13-753b-49cd-9851-f6e391e8c474",
   "metadata": {},
   "source": [
    "Inspect the shape of the the first training sample, it is an 28 x 28 greyscale image and a lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47205f45-e374-43a3-8cd5-e1ffc350e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"datatype of the 1st training sample: \", train_dataset[0][0].type())\n",
    "print(\"size of the 1st training sample: \", train_dataset[0][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c34c0-53dd-4511-9c53-fdafecb96173",
   "metadata": {},
   "source": [
    "And the label of the first two samplea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf9ca4-78d1-4a5f-b809-f36ffdaa7894",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"label of the first training sample: \", train_dataset[0][1])\n",
    "print(\"label of the second training sample: \", train_dataset[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3ba4a-f539-45fb-96c8-739aa63668cc",
   "metadata": {},
   "source": [
    "Display the two images to confirm what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f17e08-48d4-41ed-ad8f-6d1d90862551",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_5 = train_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img_5, cmap='gray')\n",
    "plt.show()\n",
    "img_0 = train_dataset[1][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img_0, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2a766-dfaa-4ead-bd02-4a503b2f383c",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "The data will be read in batches of 32 samples by using a DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "391f2e43-2e91-4c1d-bb9c-3ab872b6f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batach_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batach_size, shuffle=True) \n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batach_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2ba83-1abb-4b91-aae1-f80bb67eb26d",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "Notice that we are setting the algorithm to Logistic Regression and the using the Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc3fa3b-d791-4780-9d20-cf8568df4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):    \n",
    "   \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5b049-e96f-43d0-9394-1c12d5c972f9",
   "metadata": {},
   "source": [
    "The previous step defined a module to do the work, so now you just need to create an instance of it\n",
    "\n",
    "Notice the inputs are the 28x28 array of pixels are mapped into a single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe8fe9a3-7743-4384-a110-ac0dcd818c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_outputs = 10\n",
    "log_regr = LogisticRegression(n_inputs, n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded379b-9f86-42b2-8f04-e63fbbf17760",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now the actual training begins. \n",
    "- The loss function is cross-entropy loss\n",
    "- The training cost function optimization is stochastic gradient descent\n",
    "- Remember that stochastic GD uses epochs to train, you will train for 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c571151-8798-43a4-bcc3-4490a06275c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(log_regr.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fc3b2-15f4-47a3-b892-6a4e9210429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = []\n",
    "acc = []\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = log_regr(images.view(-1, 28*28))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    Loss.append(loss.item())\n",
    "    correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = log_regr(images.view(-1, 28*28))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "    accuracy = 100 * (correct.item()) / len(test_dataset)\n",
    "    acc.append(accuracy)\n",
    "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8756b1d-9678-4e78-b4e3-bb7d0d01ca10",
   "metadata": {},
   "source": [
    "## Examine the rate of loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141100bf-d27e-414f-b67b-5086f8fdcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss)\n",
    "plt.xlabel(\"no. of epochs\")\n",
    "plt.ylabel(\"total loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e95220-9221-4dea-b6ff-b737df4d08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)\n",
    "plt.xlabel(\"no. of epochs\")\n",
    "plt.ylabel(\"total accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d292a-78de-4f70-9143-720d13897bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
